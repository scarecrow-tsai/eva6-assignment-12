{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Assignment 11"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "from app.models.transformer import SpatialTransformer\n",
    "from app.utils.transforms import transforms\n",
    "from app.datasets.cifar10 import load_cifar10\n",
    "from app.explainability.gradcam import GradCAM\n",
    "from app.utils.misc import set_seed, tensor_to_image\n",
    "from app.utils.train_test_loops import train_loop, test_loop\n",
    "from app.utils.result_stats import loss_acc_curves, score_report\n",
    "from app.utils.result_analysis import (\n",
    "    get_misclassified_info,\n",
    "    visualize_misclassified_images,\n",
    "    misclassified_gradcam\n",
    ")\n",
    "\n",
    "from app.utils.lr_finder import LRFinder\n",
    "\n",
    "from app.utils.dataset import (\n",
    "    calc_data_stats,\n",
    "    visualise_transforms,\n",
    "    class_to_idx,\n",
    "    idx_to_class,\n",
    ")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "set_seed(69)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "################################\n",
    "## CONFIG\n",
    "################################\n",
    "\n",
    "DATASET_NAME = \"cifar10\"\n",
    "DATASET_PATH = f\"./../data/{DATASET_NAME}/\"\n",
    "NUM_CLASSES = 10\n",
    "NUM_INPUT_CHANNELS = 3\n",
    "\n",
    "BATCH_SIZE = 256\n",
    "EPOCHS = 1\n",
    "LEARNING_RATE = 1e-7\n",
    "\n",
    "# SET GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"\\nWe're using =>\", device)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "################################\n",
    "## LOAD DATASET\n",
    "################################\n",
    "\n",
    "# datasets\n",
    "og_dataset = load_cifar10(\n",
    "    dataset_path=DATASET_PATH, is_train=False, image_transforms=ToTensorV2(),\n",
    ")\n",
    "\n",
    "# calculate dataset mean and std\n",
    "dataset_mean, dataset_std = calc_data_stats(og_dataset)\n",
    "\n",
    "image_transforms = transforms(dataset_mean, dataset_std)\n",
    "\n",
    "train_dataset = load_cifar10(\n",
    "    dataset_path=DATASET_PATH,\n",
    "    is_train=True,\n",
    "    image_transforms=image_transforms[\"train\"],\n",
    ")\n",
    "\n",
    "test_dataset = load_cifar10(\n",
    "    dataset_path=DATASET_PATH,\n",
    "    is_train=False,\n",
    "    image_transforms=image_transforms[\"test\"],\n",
    ")\n",
    "\n",
    "\n",
    "class2idx = class_to_idx(og_dataset.classes)\n",
    "idx2class = idx_to_class(class2idx)\n",
    "\n",
    "\n",
    "visualise_transforms(\n",
    "    original_data=og_dataset, transformed_data=train_dataset, num_samples=10\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "################################\n",
    "## CREATE DATALOADERS\n",
    "################################\n",
    "\n",
    "# dataloader\n",
    "train_loader = DataLoader(dataset=train_dataset, shuffle=False, batch_size=BATCH_SIZE)\n",
    "\n",
    "val_loader = DataLoader(dataset=train_dataset, shuffle=False, batch_size=BATCH_SIZE)\n",
    "\n",
    "test_loader = DataLoader(dataset=test_dataset, shuffle=False, batch_size=BATCH_SIZE)\n",
    "\n",
    "## Data Sanity Check\n",
    "print(f\"\\nTrain loader = {next(iter(train_loader))[0].shape}\")\n",
    "print(f\"Val loader = {next(iter(val_loader))[0].shape}\")\n",
    "print(f\"Test loader = {next(iter(test_loader))[0].shape}\")\n",
    "print(f\"\\nTrain loader length = {len(train_loader)}\")\n",
    "print(f\"Val loader length = {len(val_loader)}\")\n",
    "print(f\"Test loader length = {len(test_loader)}\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "################################\n",
    "## LOAD MODEL\n",
    "################################\n",
    "\n",
    "model = SpatialTransformer(num_input_channels=NUM_INPUT_CHANNELS, num_classes=NUM_CLASSES)\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.99)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from app.utils.lr_finder import LRFinder\n",
    "\n",
    "lr_finder = LRFinder(model=model, criterion=criterion, optimizer=optimizer, device=device)\n",
    "LEARNING_RATE = lr_finder.run(dataloader=train_loader)\n",
    "lr_finder.plot()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "LEARNING_RATE = 0.001\n",
    "scheduler = optim.lr_scheduler.OneCycleLR(optimizer,\n",
    "                                          max_lr=round(0.001, 3),\n",
    "                                          steps_per_epoch=len(train_loader),\n",
    "                                          epochs=EPOCHS)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "###########################\n",
    "## Train Loop\n",
    "################################\n",
    "trained_model, loss_stats, acc_stats = train_loop(\n",
    "    model=model,\n",
    "    epochs=EPOCHS,\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion,\n",
    "    scheduler=scheduler,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "\n",
    "loss_acc_curves(loss_stats=loss_stats, acc_stats=acc_stats)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "################################\n",
    "## Test Loop\n",
    "################################\n",
    "y_pred_list, y_true_list = test_loop(\n",
    "    model=trained_model, test_loader=test_loader, device=device,\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "################################\n",
    "## Result Stats\n",
    "################################\n",
    "print(score_report(y_true_list, y_pred_list, idx2class))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "################################\n",
    "## Result Analysis\n",
    "################################\n",
    "\n",
    "def get_misclassified_info(y_pred_list, y_true_list):\n",
    "    return [\n",
    "        {\"idx\": i, \"pred\": pred, \"true\": actual}\n",
    "        for i, (pred, actual) in enumerate(zip(y_pred_list, y_true_list))\n",
    "        if pred != actual\n",
    "    ]\n",
    "\n",
    "\n",
    "misclassified_info = get_misclassified_info(\n",
    "    y_pred_list=y_pred_list, y_true_list=y_true_list\n",
    ")\n",
    "\n",
    "\n",
    "visualize_misclassified_images(\n",
    "    misclassified_info=misclassified_info,\n",
    "    dataset=og_dataset,\n",
    "    idx_to_class=idx2class,\n",
    "    num_samples=11,\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "################################\n",
    "## GradCAM\n",
    "################################\n",
    "x_test, y_test = test_dataset[40]\n",
    "\n",
    "\n",
    "tensor_to_image(x_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "cam = GradCAM(\n",
    "    model=trained_model, target_layer=trained_model.layer_2.base_layer[-1].base_block[-1][0]\n",
    ")\n",
    "\n",
    "output = cam(x_test.to(device))\n",
    "\n",
    "\n",
    "plt.imshow(output)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "misclassified_gradcam(\n",
    "    model = trained_model,\n",
    "    misclassified_info=misclassified_info,\n",
    "    dataset=test_dataset,\n",
    "    idx_to_class=idx2class,\n",
    "    num_samples=10,\n",
    "    device=device\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6e3d2c493437c593e61b7d8e5a7a0e8be3d41f4ffb148d8ff63dbcc244e01410"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('toothless': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}